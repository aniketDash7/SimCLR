{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR Downstream Task: UC Merced Land Use Classification\n",
    "\n",
    "This notebook adapts a pretrained SimCLR (ResNet-101) model for the UC Merced Land Use dataset.\n",
    "It includes:\n",
    "1.  **Data Loading**: Automatic download of UC Merced dataset.\n",
    "2.  **Model Loading**: Loading the pretrained SimCLR weights.\n",
    "3.  **Fine-Tuning**: Training the full model on the new dataset.\n",
    "4.  **Visualization**: 3D t-SNE animation of the embeddings.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Ensure you have uploaded `simclr_model_RN101.pth` to the Colab runtime (Files tab on the left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Definition (SimCLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_NUM = 1e9\n",
    "\n",
    "def nt_xent(z: torch.Tensor, perm: torch.Tensor, tau: float) -> torch.Tensor:\n",
    "    features = F.normalize(z, dim=1)\n",
    "    sim = features @ features.T\n",
    "    sim.fill_diagonal_(-LARGE_NUM)\n",
    "    sim /= tau\n",
    "    return F.cross_entropy(sim, perm)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, tau: float, feat_dim: int = 256):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.tau = tau\n",
    "        z_dim = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(z_dim, feat_dim, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        b = x1.size(0)\n",
    "        xp = torch.cat((x1, x2))\n",
    "        perm = torch.cat((torch.arange(b) + b, torch.arange(b)), dim=0).to(x1.device)\n",
    "        h = self.backbone(xp)\n",
    "        z = self.projection_head(h)\n",
    "        return nt_xent(z, perm, tau=self.tau)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            h = self.backbone(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading (UC Merced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_uc_merced(root):\n",
    "    url = \"http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\"\n",
    "    target_dir = os.path.join(root, \"UCMerced_LandUse\")\n",
    "    if os.path.exists(target_dir):\n",
    "        print(f\"Dataset folder found at {target_dir}\")\n",
    "        images_dir = os.path.join(target_dir, \"Images\")\n",
    "        if os.path.exists(images_dir):\n",
    "             return images_dir\n",
    "        return target_dir\n",
    "\n",
    "    print(f\"Downloading UC Merced dataset from {url}...\")\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    zip_path = os.path.join(root, \"UCMerced_LandUse.zip\")\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "    with open(zip_path, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "    \n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(root)\n",
    "    \n",
    "    images_dir = os.path.join(root, \"UCMerced_LandUse\", \"Images\")\n",
    "    if not os.path.exists(images_dir):\n",
    "        return os.path.join(root, \"UCMerced_LandUse\")\n",
    "    return images_dir\n",
    "\n",
    "def get_uc_merced_loader(root, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    data_dir = download_uc_merced(root)\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42, stratify=dataset.targets)\n",
    "    train_ds = torch.utils.data.Subset(dataset, train_idx)\n",
    "    test_ds = torch.utils.data.Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return train_loader, test_loader, dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        num_ftrs = 2048 \n",
    "        self.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=15):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    features = model.backbone(inputs)\n",
    "                    outputs = model.classifier(features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"simclr_model_RN101.pth\"\n",
    "DATA_DIR = \"./data\"\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 1. Load Data\n",
    "train_loader, test_loader, class_names = get_uc_merced_loader(DATA_DIR, BATCH_SIZE)\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "\n",
    "# 2. Load Pretrained Model\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"WARNING: {MODEL_PATH} not found. Please upload it to Colab.\")\n",
    "else:\n",
    "    print(\"Loading pretrained SimCLR model...\")\n",
    "    backbone = models.resnet101(weights=None)\n",
    "    simclr_model = SimCLR(backbone=backbone, tau=0.1)\n",
    "    try:\n",
    "        state_dict = torch.load(MODEL_PATH, map_location=device)\n",
    "        simclr_model.load_state_dict(state_dict)\n",
    "    except:\n",
    "        full_model = torch.load(MODEL_PATH, map_location=device)\n",
    "        simclr_model.load_state_dict(full_model.state_dict())\n",
    "    \n",
    "    # 3. Setup Fine-Tuning\n",
    "    backbone = simclr_model.backbone\n",
    "    for param in backbone.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    model = FineTuneModel(backbone, num_classes=len(class_names)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.backbone.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "    ])\n",
    "    \n",
    "    # 4. Train\n",
    "    model, hist = train_model(model, dataloaders, criterion, optimizer, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tsne(model, loader, device, save_path=\"tsne_animation.gif\"):\n",
    "    print(\"Extracting features for t-SNE...\")\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            # Extract from backbone\n",
    "            feats = model.backbone(inputs)\n",
    "            features_list.append(feats.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    print(\"Computing 3D t-SNE...\")\n",
    "    tsne = TSNE(n_components=3, perplexity=30, n_iter=1000, random_state=42)\n",
    "    projections = tsne.fit_transform(features)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    classes = np.unique(labels)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(classes)))\n",
    "    \n",
    "    scatters = []\n",
    "    for i, c in enumerate(classes):\n",
    "        mask = labels == c\n",
    "        scatters.append(ax.scatter(projections[mask, 0], projections[mask, 1], projections[mask, 2], \n",
    "                                   label=f\"Class {c}\", s=20, alpha=0.6, color=colors[i]))\n",
    "    ax.set_title(\"3D t-SNE of Fine-Tuned Embeddings\")\n",
    "    \n",
    "    def update(angle):\n",
    "        ax.view_init(elev=30, azim=angle)\n",
    "        return scatters\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=False)\n",
    "    ani.save(save_path, writer='pillow', fps=20)\n",
    "    print(f\"Animation saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_tsne(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
